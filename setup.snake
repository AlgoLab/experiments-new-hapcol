#
# for generating all of the data needed for the experiments
#----------------------------------------------------------------------
#
data_dir = '/data/phasing-comparison-experiments'
hap_dir = '/home/prj_rnabwt/haplotyping'

# scripts and programs
time = '/usr/bin/time'
whatshap = 'programs/whatshap/venv/bin/whatshap'
scripts = ['wiftools.py', 'subvcf.py']
scripts_regex = '('+'|'.join([s for s in scripts])+')'

# datasets
data = ['ashk', 'sim']
platforms = ['pacbio']
individuals = ['child'] # mother, father, ..
chromosomes = [1, 21]
coverages = [5, 10, 15, 20, 25, 30, 'all']
high_coverages = [40, 50, 60]

# whatshap processing
realignment = ['raw', 'realigned'] # whatshap realignment
hs = [15, 20, 25, 30, 'N'] # whatshap read selection

# remaining processing
seeds = [1] # 2, 3, .. for (pseudo-) random downsampling
max_covs = [15, 20, 25, 30]

# common patterns
vcf_pattern = '{dataset,[a-z]+}.{individual,(mother|father|child)}.chr{chromosome,[0-9]+}'
dataset_pattern = '{dataset,[a-z]+}.{platform,[a-z]+}.{individual,(mother|father|child)}.chr{chromosome,[0-9]+}.cov{coverage,(all|[0-9]+)}'
whatshap_pattern = dataset_pattern + '.{realignment,(raw|realigned)}.h{h,([0-9]+|N)}'
post_pattern = whatshap_pattern + '{mergebefore,(|.merged)}{downsample,(|.sh[0-9]+-max[0-9]+)}{mergeafter,(|.merged)}'
full_pattern = post_pattern + '{ea,(|.[0-9]+_[0-9]+)}{balancing,(|.balanced)}'

# common lists
datasets = ['{}.pacbio.child.chr{}.cov{}.{}'.format(data, chromosome, coverage, mode)
	for data in data
	for chromosome in chromosomes
	for coverage in coverages + high_coverages
	for mode in realignment]

whatshap_downsample = ['{}.h{}'.format(dataset, h)
	for dataset in datasets
	for h in hs]

post_whatshap = ['{}.hN{}sh1-max{}'.format(dataset, merge, max)
	for dataset in datasets
	for merge in ['.', '.merged.']
        for max in max_covs]

#
# master rule
#----------------------------------------------------------------------
rule setup :
	input :
		expand('wif/{pattern}.wif.info_/block_sites_',
			pattern = whatshap_downsample + post_whatshap),

		expand('vcf/{data}.child.chr{chr}.phased.vcf',
			data = data,
			chr = chromosomes)

#
# link to a script in the haplotyping/scripts directory, etc.
#----------------------------------------------------------------------
rule link_script :
        input : hap_dir + '/scripts/{script}'
	output : 'scripts/{script,' + scripts_regex + '}'
	message : 'linking script {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

#
# link to files from phasing comparison experiments directory
#----------------------------------------------------------------------
rule link_vcf :
	input : data_dir + '/vcf/' + vcf_pattern + '.{phase,(phased|unphased)}.vcf'
	output : 'vcf/' + vcf_pattern + '.{phase,(phased|unphased)}.vcf'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

# from where we link the bam (bai) depends on the coverage
def bam_source_link(wildcards) :

	supp = ''
	cov = wildcards.coverage

	if wildcards.coverage in [str(c) for c in high_coverages] :
		supp = '-cov60'

		if wildcards.coverage == '60' :
			cov = 'all'

	return '{}{}/bam/{}.{}.{}.chr{}.cov{}.{}'.format(
		data_dir, supp,
		wildcards.dataset,
		wildcards.platform,
		wildcards.individual,
		wildcards.chromosome,
		cov, wildcards.ext)

rule link_bam_bai :
	input : bam_source_link
	output : 'bam/' + dataset_pattern + '.{ext,(bam|bai)}'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

rule link_reference :
	input : data_dir + '/reference/human_g1k_v37.fasta'
	output : 'reference/human_g1k_v37.fasta'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

#
# obtain a wif file from a bam / vcf pair using whatshap
#----------------------------------------------------------------------
rule get_wif :
	input :
		bam = 'bam/' + dataset_pattern + '.bam',
		vcf = 'vcf/' + vcf_pattern + '.unphased.vcf',
		ref = 'reference/human_g1k_v37.fasta'

	params :
                realignment = lambda wildcards, input :
			'--reference '+input.ref if wildcards.realignment == 'realigned' else '',
		h = lambda wildcards :
			'1000' if wildcards.h == 'N' else wildcards.h

	output : 'wif/' + whatshap_pattern + '.wif'

	log :
		transcript = 'wif/' + whatshap_pattern + '.wif.transcript',
		log = 'wif/' + whatshap_pattern + '.wif.log',
		time = 'wif/' + whatshap_pattern + '.wif.time'

	message : '''

   obtaining wif file {output} from {input.bam} / {input.vcf} pair,
   after selecting reads down to max coverage {params.h} '''

	shell : '''
   
   {time} -v -o {log.time} \
      {whatshap} phase -o /dev/null {params.realignment} \
         --output-wif {output} -H {params.h} \
         {input.vcf} {input.bam} > {log.transcript} 2> {log.log} '''

#
# downsample a wif file to a specified max coverage
#----------------------------------------------------------------------
rule extract_sample :
	input :
		source = '{path}.wif',
		sample = '{path}.wif.sample_s{seed}_m{max}'

	output : '{path}.downs_s{seed,[0-9]+}_m{max,[0-9]+}.wif'
	message : 'extract lines {input.sample} from {input.source}'

	shell : '''

   awk '{{printf "%.20d %s\\n", NR, $0}}' {input.source} | join - \
      <(awk '{{printf "%.20d\\n", $1}}' {input.sample} | sort) | \
         sed 's/^[0-9]* //' > {output} '''

# greedily downsample wif to a coverage according to a shuffle
rule downsample :
	input :
		script = 'scripts/wiftools.py',
		wif = '{path}.wif',
		shuf = '{path}.wif.lines.shuf{seed}'

	output : '{path}.wif.sample_s{seed,[0-9]+}_m{max,[0-9]+}'

	log :
		log = '{path}.wif.sample_s{seed}_m{max}.log',
		time = '{path}.wif.sample_s{seed}_m{max}.time'

	message : '''

   psuedorandom downsampling of {input.wif} to coverage {wildcards.max}
   according to {input.shuf} '''

	shell : '''

   {time} -v -o {log.time} \
      python {input.script} -s {wildcards.max} {input.shuf} {input.wif} \
         > {output} 2> {log.log} '''

# seeded pseudorandom shuffle of lines of a file (cf. gnu.org)
rule permute_lines :
	input : '{path}.lines'
	output : '{path}.lines.shuf{seed,[0-9]+}'
	message : 'pseudorandom shuffle of {input} with seed {wildcards.seed}'
	shell : '''

   shuf {input} --random-source=<(openssl enc -aes-256-ctr \
      -pass pass:"{wildcards.seed}" -nosalt </dev/zero 2>/dev/null) > {output} '''

# get lines (numbers) from a file
rule get_lines :
	input : '{path}'
	output : '{path}.lines'
	message : 'obtain lines (numbers) from {input}'
	shell : ''' awk '{{print NR}}' {input} > {output} '''

#
# obtain a (red-blue-) merged wif from a wif
#----------------------------------------------------------------------
rule merge_wif :
	input :
		script = 'scripts/rb-merge.py',
		wif = '{path}.wif'

	params :
		e = lambda wildcards : '0.' + wildcards.err,
		m = lambda wildcards : '0.' + wildcards.max,
		t = lambda wildcards : 10 ** int(wildcards.thresh),
		n = lambda wildcards : 10 ** int(wildcards.neg)

	output : '{path}.merged_e{err,[0-9]+}_m{max,[0-9]+}_t{thresh,[0-9]+}_n{neg,[0-9]+}.wif'

	log :
		log = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.log',
		time = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.time',
		graph = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.graph'

	message : '''

   merge reads of {input.wif},
   with parameters:

   error rate = {params.e},
   max error rate = {params.m},
   threshold = {params.t},
   neg. threshold = {params.n}

   producing: {output} '''

	shell : '''

   {time} -v -o {log.time} \
      python {input.script} -v -e {params.e} -m {params.m} \
         -t {params.t} -n {params.n} -w {input.wif} -o {output} \
         -g {log.graph} > {log.log} 2>&1 '''

#
# obtain properties of a wif file
#----------------------------------------------------------------------
rule wif_info :
	input :
		script = 'scripts/wiftools.py',
		wif = '{path}.wif'

	output : '{path}.wif.info_/block_sites_'
	message : 'obtaining info for {input.wif}'
	shell : 'python {input.script} -i {input.wif}'
