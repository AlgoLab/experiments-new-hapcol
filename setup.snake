#
# for generating all of the data needed for the experiments
#----------------------------------------------------------------------
#
data_dir = '/data/phasing-comparison-experiments-hapcol'
hap_dir = '/home/prj_rnabwt/haplotyping'

# scripts and programs
time = '/usr/bin/time'
phase = 'programs/whatshap/venv/bin/whatshap phase'
scripts = ['wiftools.py', 'subvcf.py']
scripts_regex = '('+'|'.join([s for s in scripts])+')'

# datasets
data = ['ashk', 'sim']
platforms = ['pacbio']
individuals = ['child'] # mother, father, ..
chromosomes = [1, 21]
coverages = list(range(15, 65, 5)) # 15, 20, .., 60
chr_covs = {  1 : coverages,
             21 : list(range(15, 55, 5)) } # just 15, 20, .., 50 for chr21

# whatshap processing
realignment_modes = ['raw', 'realigned'] # whatshap realignment
hs = coverages  # whatshap read selection

# merging
merge_pattern = '.merged_e[0-9]+_m[0-9]+_t[0-9]+_n[0-9]+'
error_rates = [15]
max_errs = [25]
thresholds = [6, 7, 17]
neg_threshs = [3]
mergings = ['.merged_e{}_m{}_t{}_n{}'.format(err, max, thresh, neg)
	for err in error_rates
	for max in max_errs
	for thresh in thresholds
	for neg in neg_threshs] + ['.no_merging']

# downsampling to a max coverage (in a random greedy way)
downsample_pattern = '.downs_s[0-9]+_m[0-9]+'
seeds = [1] # 2, 3, .. for (pseudo-) random downsampling
max_covs = coverages
downsamplings = ['.downs_s{}_m{}'.format(seed, max)
	for seed in seeds
	for max in max_covs] + ['.no_downs']

# common patterns
vcf_pattern = '{dataset,[a-z]+}.{individual,(mother|father|child)}.chr{chromosome,[0-9]+}'
dataset_pattern = '{dataset,[a-z]+}.{platform,[a-z]+}.{individual,(mother|father|child)}.chr{chromosome,[0-9]+}.cov{coverage,(all|[0-9]+)}'
whatshap_pattern = dataset_pattern + '.{realignment,(raw|realigned)}.h{h,([0-9]+|N)}'
post_pattern = whatshap_pattern + '{mergebefore,(.no_merging|' + merge_pattern + ')}{downsample,(.no_downs|' + downsample_pattern + ')}{mergeafter,(.no_merging|' + merge_pattern + ')}'

# common lists
datasets = ['{}.pacbio.child.chr{}.cov{}.{}'.format(data, chromosome, coverage, mode)
	for data in data
	for chromosome in chromosomes
	for coverage in chr_covs[chromosome]
	for mode in realignment_modes]

whatshap_downsample = ['{}.h{}.no_merging.no_downs.no_merging'.format(dataset, h)
	for dataset in datasets
	for h in hs]

post_whatshap = ['{}.hN{}{}.no_merging'.format(dataset, merging, downsampling)
	for dataset in datasets
	for merging in mergings
	for downsampling in downsamplings]

#
# master rule
#----------------------------------------------------------------------
rule setup :
	input :
		expand('wif/{pattern}.wif.info_/block_sites_',
			pattern = whatshap_downsample + post_whatshap),

		expand('vcf/{data}.child.chr{chr}.phased.vcf',
			data = data,
			chr = chromosomes)

#
# link to a script in the haplotyping/scripts directory, etc.
#----------------------------------------------------------------------
rule link_script :
        input : hap_dir + '/scripts/{script}'
	output : 'scripts/{script,' + scripts_regex + '}'
	message : 'linking script {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

#
# link to files from phasing comparison experiments directory
#----------------------------------------------------------------------
rule link_vcf :
	input : data_dir + '/vcf/' + vcf_pattern + '.{phase,(phased|unphased)}.vcf'
	output : 'vcf/' + vcf_pattern + '.{phase,(phased|unphased)}.vcf'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

# from where we link the bam (bai) depends on the coverage
def bam_source_link(wildcards) :

	supp = ''
	cov = wildcards.coverage

	if wildcards.coverage in [str(c) for c in high_coverages] :
		supp = '-cov60'

		if wildcards.coverage == '60' :
			cov = 'all'

	return '{}{}/bam/{}.{}.{}.chr{}.cov{}.{}'.format(
		data_dir, supp,
		wildcards.dataset,
		wildcards.platform,
		wildcards.individual,
		wildcards.chromosome,
		cov, wildcards.ext)

rule link_bam_bai :
	input : bam_source_link
	output : 'bam/' + dataset_pattern + '.{ext,(bam|bai)}'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

rule link_reference :
	input : data_dir + '/reference/human_g1k_v37.fasta'
	output : 'reference/human_g1k_v37.fasta'
	message : 'linking {input} to {output}'
	shell : 'ln -fsrv {input} {output}'

#
# obtain a wif file from a bam / vcf pair using whatshap
#----------------------------------------------------------------------
rule get_wif :
	input :
		bam = 'bam/' + dataset_pattern + '.bam',
		vcf = 'vcf/' + vcf_pattern + '.unphased.vcf',
		ref = 'reference/human_g1k_v37.fasta'

	params :
                realignment = lambda wildcards, input :
			'--reference '+input.ref if wildcards.realignment == 'realigned' else '',
		h = lambda wildcards :
			'1000' if wildcards.h == 'N' else wildcards.h

	output : 'wif/' + whatshap_pattern + '.wif'

	log :
		transcript = 'wif/' + whatshap_pattern + '.wif.transcript',
		log = 'wif/' + whatshap_pattern + '.wif.log',
		time = 'wif/' + whatshap_pattern + '.wif.time'

	message : '''

   obtaining wif file {output} from {input.bam} / {input.vcf} pair,
   after selecting reads down to max coverage {params.h} '''

	shell : '''
   
   {time} -v -o {log.time} \
      {phase} -o /dev/null {params.realignment} \
         --output-wif {output} -H {params.h} \
         {input.vcf} {input.bam} > {log.transcript} 2> {log.log} '''

#
# downsample a wif file to a specified max coverage
#----------------------------------------------------------------------
rule extract_sample :
	input :
		source = '{path}.wif',
		sample = '{path}.wif.sample_s{seed}_m{max}'

	output : '{path}.downs_s{seed,[0-9]+}_m{max,[0-9]+}.wif'
	message : 'extract lines {input.sample} from {input.source}'

	shell : '''

   awk '{{printf "%.20d %s\\n", NR, $0}}' {input.source} | join - \
      <(awk '{{printf "%.20d\\n", $1}}' {input.sample} | sort) | \
         sed 's/^[0-9]* //' > {output} '''

# dummy rule to ensure the naming is consistent
rule no_downsampling :
	input : '{path}.wif'
	output : '{path}.no_downs.wif'
	message : 'perform no downsampling'
	shell : 'cp {input} {output}'

# greedily downsample wif to a coverage according to a shuffle
rule downsample :
	input :
		script = 'scripts/wiftools.py',
		wif = '{path}.wif',
		shuf = '{path}.wif.lines.shuf{seed}'

	output : '{path}.wif.sample_s{seed,[0-9]+}_m{max,[0-9]+}'

	log :
		log = '{path}.wif.sample_s{seed}_m{max}.log',
		time = '{path}.wif.sample_s{seed}_m{max}.time'

	message : '''

   psuedorandom downsampling of {input.wif} to coverage {wildcards.max}
   according to {input.shuf} '''

	shell : '''

   {time} -v -o {log.time} \
      python {input.script} -s {wildcards.max} {input.shuf} {input.wif} \
         > {output} 2> {log.log} '''

# seeded pseudorandom shuffle of lines of a file (cf. gnu.org)
rule permute_lines :
	input : '{path}.lines'
	output : '{path}.lines.shuf{seed,[0-9]+}'
	message : 'pseudorandom shuffle of {input} with seed {wildcards.seed}'
	shell : '''

   shuf {input} --random-source=<(openssl enc -aes-256-ctr \
      -pass pass:"{wildcards.seed}" -nosalt </dev/zero 2>/dev/null) > {output} '''

# get lines (numbers) from a file
rule get_lines :
	input : '{path}'
	output : '{path}.lines'
	message : 'obtain lines (numbers) from {input}'
	shell : ''' awk '{{print NR}}' {input} > {output} '''

#
# obtain a (red-blue-) merged wif from a wif
#----------------------------------------------------------------------
rule merge_wif :
	input :
		script = 'scripts/rb-merge.py',
		wif = '{path}.wif'

	params :
		e = lambda wildcards : '0.' + wildcards.err,
		m = lambda wildcards : '0.' + wildcards.max,
		t = lambda wildcards : 10 ** int(wildcards.thresh),
		n = lambda wildcards : 10 ** int(wildcards.neg)

	output : '{path}.merged_e{err,[0-9]+}_m{max,[0-9]+}_t{thresh,[0-9]+}_n{neg,[0-9]+}.wif'

	log :
		log = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.log',
		time = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.time',
		graph = '{path}.merged_e{err}_m{max}_t{thresh}_n{neg}.wif.graph'

	message : '''

   merge reads of {input.wif},
   with parameters:

   error rate = {params.e},
   max error rate = {params.m},
   threshold = {params.t},
   neg. threshold = {params.n}

   producing: {output} '''

	shell : '''

   {time} -v -o {log.time} \
      python {input.script} -v -e {params.e} -m {params.m} \
         -t {params.t} -n {params.n} -w {input.wif} -o {output} \
         -g {log.graph} > {log.log} 2>&1 '''

# dummy rule to ensure the naming is consistent
rule no_merging :
	input : '{path}.wif'
	output : '{path}.no_merging.wif'
	message : 'perform no merging'
	shell : 'cp {input} {output}'

#
# obtain properties of a wif file
#----------------------------------------------------------------------
rule wif_info :
	input :
		script = 'scripts/wiftools.py',
		wif = '{path}.wif'

	output :
		expand('{{path}}.wif.info_/{file}',
			file = ['block_reads_', 'block_sites_',
				'site_alleles_', 'site_zygosity_',
				'blocks_', 'reads_',
				'sites_', 'stats_'])

	message : 'obtaining info for {input.wif}'
	shell : 'python {input.script} -i {input.wif}'
